#
# Copyright 2015 VMware, Inc.  All rights reserved.
# SPDX-License-Identifier: Apache-2.0 OR GPL-3.0-only
#
---
- name: create docker build dir
  file: state=directory path={{ elasticsearch_docker_build }}

# we don't have rsync for photon yet, so use copy.
# copy doesn't have exclude and fails on the .git dir, so
# we use the with_fileglob to avoid getting .git
- name: sync the docker image src to remote nodes
  copy: src={{ item }} dest={{ elasticsearch_docker_build }} mode=755
  with_fileglob:
    - ../../../../containers/docker/elasticsearch/*

- name: build the image
  async: 1000
  shell: cd {{ elasticsearch_docker_build }} && /bin/bash ./build.sh

- name: docker run elasticsearch server
  docker:
    docker_api_version: "{{ docker_api_version }}"
    name: elasticsearch
    image: "{{ elasticsearch_docker_image }}"
    command: elasticsearch
    memory_limit: "{{ memory_limit }}"
    restart_policy: always
    state: reloaded
    env:
      PUBLISHHOST: "{{ hostvars[inventory_hostname]['ansible_eth0']['ipv4']['address'] }}"
      CLUSTERNAME: "{{ elasticsearch_cluster_name }}"
      LOGLEVEL: "{{ elasticsearch_log_level }}"
    expose:
      - 9200
      - 9300
    ports:
      # we bind to the standard ports on the host,
      # means we can only run one ES instance per host, but
      # until I learn a way to inform the ES service about it's
      # mapped port, we must.
      - 9200:9200
      - 9300:9300
# left here as a note that these volumes are exposed on the image
# might need that info for backups later.
#    volumes:
#      - "{{ elasticsearch_mapped_dir }}/data:/usr/share/elasticsearch/data"
#      - "{{ elasticsearch_mapped_dir }}/config:/usr/share/elasticsearch/config"
#      - "{{ elasticsearch_mapped_dir }}/logs:/usr/share/elasticsearch/logs"

- name: wait for elastic search to start
  wait_for: port=9200 delay=1

- name: test health
  shell: curl --retry 3 --retry-delay 5 -XGET 'http://localhost:9200/_cluster/health?pretty=true'
  register: health

- debug: msg="{{ health.stdout }}"
